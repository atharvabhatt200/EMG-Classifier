{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = (256, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapDataset(Dataset):\n",
    "    def __init__(self, annotation_file):\n",
    "        self.annotations = pd.read_csv(annotation_file)\n",
    "        self.transform = transforms.Compose([None])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_vec = torch.tensor(self.annotations.iloc[index, 1:], dtype=torch.float)\n",
    "        img = torch.reshape(img_vec,(1, sz[1], sz[0]))\n",
    "        # img = torch.transpose(img,1,2)\n",
    "\n",
    "        y_label = torch.tensor(self.annotations.iloc[index, 0],dtype=torch.long)\n",
    "        # if (y_label <= 61 ):\n",
    "        #     img = torch.transpose(img,1,2)\n",
    "\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = CapDataset(\"output_test_large.csv\")\n",
    "test_loader = DataLoader(dataset=dataset_test, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import SpinalVGG\n",
    "# from segmentation import Segmentation\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = 'cuda'\n",
    "model1 = SpinalVGG().to(device)\n",
    "model1.load_state_dict(torch.load(\"model_large_rect_optimal.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21032\\43906973.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_vec = torch.tensor(self.annotations.iloc[index, 1:], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "tp = tn = fp = fn = total1 = correct1 = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model1(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total1 += labels.size(0)\n",
    "            correct1 += (predicted == labels).sum().item()\n",
    "            tp += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            tn += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            fp += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            fn += ((predicted == 0) & (labels == 1)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9518072289156626\n",
      "Threshold=0.500000, F-Score=0.949, Precision=0.940, Recall=0.958\n",
      "297 19 13 335\n"
     ]
    }
   ],
   "source": [
    "model_precision= tp/(tp+fp)\n",
    "model_recall= tp/(tp+fn)\n",
    "model_f= 2*model_precision*model_recall/(model_precision+model_recall)\n",
    "print(\"acc\", correct1 / total1)\n",
    "print('Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (0.5, model_f, model_precision, model_recall))\n",
    "print(tp,fp,fn,tn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
